{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0e0977c-b52a-4260-b8e2-6d7b90e10f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41c68052-3de5-41a1-8120-f6926717e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = pd.read_csv(\"C:/Users/USER/Downloads/Admission_Predict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe043cf6-17ce-4968-8eb6-9dd3a5c26b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fc2738b-d82f-412a-ae0e-4dbf673c9464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90f2d31c-c00e-4227-b3d2-0caedaf80b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         400 non-null    int64  \n",
      " 1   GRE Score          400 non-null    int64  \n",
      " 2   TOEFL Score        400 non-null    int64  \n",
      " 3   University Rating  400 non-null    int64  \n",
      " 4   SOP                400 non-null    float64\n",
      " 5   LOR                400 non-null    float64\n",
      " 6   CGPA               400 non-null    float64\n",
      " 7   Research           400 non-null    int64  \n",
      " 8   Chance of Admit    400 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 28.3 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4810422-e863-4075-9fb2-6be58f7a5254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>200.500000</td>\n",
       "      <td>316.807500</td>\n",
       "      <td>107.410000</td>\n",
       "      <td>3.087500</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.452500</td>\n",
       "      <td>8.598925</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>0.724350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>115.614301</td>\n",
       "      <td>11.473646</td>\n",
       "      <td>6.069514</td>\n",
       "      <td>1.143728</td>\n",
       "      <td>1.006869</td>\n",
       "      <td>0.898478</td>\n",
       "      <td>0.596317</td>\n",
       "      <td>0.498362</td>\n",
       "      <td>0.142609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100.750000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>200.500000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.610000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>300.250000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.062500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Serial No.   GRE Score  TOEFL Score  University Rating         SOP  \\\n",
       "count  400.000000  400.000000   400.000000         400.000000  400.000000   \n",
       "mean   200.500000  316.807500   107.410000           3.087500    3.400000   \n",
       "std    115.614301   11.473646     6.069514           1.143728    1.006869   \n",
       "min      1.000000  290.000000    92.000000           1.000000    1.000000   \n",
       "25%    100.750000  308.000000   103.000000           2.000000    2.500000   \n",
       "50%    200.500000  317.000000   107.000000           3.000000    3.500000   \n",
       "75%    300.250000  325.000000   112.000000           4.000000    4.000000   \n",
       "max    400.000000  340.000000   120.000000           5.000000    5.000000   \n",
       "\n",
       "             LOR         CGPA    Research  Chance of Admit   \n",
       "count  400.000000  400.000000  400.000000        400.000000  \n",
       "mean     3.452500    8.598925    0.547500          0.724350  \n",
       "std      0.898478    0.596317    0.498362          0.142609  \n",
       "min      1.000000    6.800000    0.000000          0.340000  \n",
       "25%      3.000000    8.170000    0.000000          0.640000  \n",
       "50%      3.500000    8.610000    1.000000          0.730000  \n",
       "75%      4.000000    9.062500    1.000000          0.830000  \n",
       "max      5.000000    9.920000    1.000000          0.970000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42423bf2-b7ef-4eee-9e83-3d76bbcc1d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd895f8e-4460-40ef-b2bf-eb645b26ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns = ['Serial No.'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "130e1d65-a19a-440d-861b-48d521023b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abfe8604-a6fe-42b8-b1ce-f07925ee767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:,0:-1]\n",
    "y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29199c5d-7f5f-4f8f-8969-dc7ac110e483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "395        324          110                  3  3.5   3.5  9.04         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "397        330          116                  4  5.0   4.5  9.45         1\n",
       "398        312          103                  3  3.5   4.0  8.78         0\n",
       "399        333          117                  4  5.0   4.0  9.66         1\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c7bf33c-5f7c-4b95-ae04-cc35914c065b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "395    0.82\n",
       "396    0.84\n",
       "397    0.91\n",
       "398    0.67\n",
       "399    0.95\n",
       "Name: Chance of Admit , Length: 400, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16d55b6c-621f-47c6-a21d-51bc2153ad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2eb5ee7-69ed-4db6-a16f-ebdd0892bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size = 0.25,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b1bcfb7-3479-4f9c-af94-3ee8f8ad1f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>320</td>\n",
       "      <td>110</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>311</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>307</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>298</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>316</td>\n",
       "      <td>109</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>307</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>321</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>326</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>300</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "82         320          110                  5  5.0   4.5  9.22         1\n",
       "367        311           98                  1  1.0   2.5  7.46         0\n",
       "179        307          102                  3  3.0   3.0  8.27         0\n",
       "27         298           98                  2  1.5   2.5  7.50         1\n",
       "89         316          109                  4  4.5   3.5  8.76         1\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "255        307          110                  4  4.0   4.5  8.37         0\n",
       "72         321          111                  5  5.0   5.0  9.45         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "235        326          111                  5  4.5   4.0  9.23         1\n",
       "37         300          105                  1  1.0   2.0  7.80         0\n",
       "\n",
       "[300 rows x 7 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06187e03-be08-4d57-9dc3-00eed6530571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "x_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0172abb-a1db-46ce-8b69-fa22bc350442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6       , 0.64285714, 1.        , ..., 0.85714286, 0.74264706,\n",
       "        1.        ],\n",
       "       [0.42      , 0.21428571, 0.        , ..., 0.28571429, 0.09558824,\n",
       "        0.        ],\n",
       "       [0.34      , 0.35714286, 0.5       , ..., 0.42857143, 0.39338235,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.7       , 0.53571429, 0.5       , ..., 0.57142857, 0.70220588,\n",
       "        1.        ],\n",
       "       [0.72      , 0.67857143, 1.        , ..., 0.71428571, 0.74632353,\n",
       "        1.        ],\n",
       "       [0.2       , 0.46428571, 0.        , ..., 0.14285714, 0.22058824,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2cc0cc28-8636-4eba-bcdb-39a26a77c1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "521e1bbd-30b9-448f-90d7-eb86a164abff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(7,activation = 'relu',input_dim = 7))\n",
    "model.add(Dense(7,activation = 'relu',input_dim = 7))\n",
    "model.add(Dense(1,activation = 'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c4b18053-18f2-4595-8f63-213b556bf1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m8\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6045f15b-334c-473c-bdd3-9d64141e0100",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error',optimizer = 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "415201f1-a08c-40fe-ac54-c65188bd6c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 2/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 3/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 4/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 5/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 6/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 7/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 8/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 9/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 10/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 11/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 12/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 13/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 14/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 15/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 16/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 17/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 18/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 19/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 20/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 21/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 22/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 23/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 24/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 25/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 26/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 27/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 28/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 29/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 30/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 31/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 32/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 33/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 34/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 35/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 36/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 37/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 38/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 39/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 40/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 41/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 42/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 43/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 44/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 45/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 46/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 47/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 48/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 49/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 50/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 51/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 52/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 53/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 54/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 55/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 56/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 57/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 58/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 59/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 60/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 61/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 62/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 63/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 64/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 65/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 66/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 67/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 68/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 69/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 70/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 71/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 72/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 73/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 74/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 75/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 76/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 77/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 78/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 79/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 80/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 81/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 82/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 83/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 84/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 85/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 86/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 87/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 88/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 89/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 90/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 91/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 92/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 93/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 94/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 95/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 96/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 97/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 98/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 99/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 100/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 101/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 102/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 103/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 104/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 105/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 106/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 107/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 108/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 109/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 110/110\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0042 - val_loss: 0.0038\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled,y_train,epochs = 110,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7f9b118c-024f-4e2b-a330-d6335de22b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "efb617df-7f09-4071-9053-6a8f5c9f0147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7911557425850905"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b7d64f98-ed16-4055-87af-abba71ed3287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x1c6903b9880>,\n",
       "  <matplotlib.axis.YTick at 0x1c69034b530>,\n",
       "  <matplotlib.axis.YTick at 0x1c690396ed0>,\n",
       "  <matplotlib.axis.YTick at 0x1c6903e9280>,\n",
       "  <matplotlib.axis.YTick at 0x1c6903e9310>,\n",
       "  <matplotlib.axis.YTick at 0x1c6903e9fd0>,\n",
       "  <matplotlib.axis.YTick at 0x1c6903ea7b0>,\n",
       "  <matplotlib.axis.YTick at 0x1c6903eae10>],\n",
       " [Text(0, 0.0, '0.00'),\n",
       "  Text(0, 0.05, '0.05'),\n",
       "  Text(0, 0.1, '0.10'),\n",
       "  Text(0, 0.15, '0.15'),\n",
       "  Text(0, 0.2, '0.20'),\n",
       "  Text(0, 0.25, '0.25'),\n",
       "  Text(0, 0.3, '0.30'),\n",
       "  Text(0, 0.35, '0.35')])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.yticks([0, 0.05, 0.1, 0.15, 0.2, 0.25,0.3,0.35])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96254c3-f32c-421d-af6c-9144278c749e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
